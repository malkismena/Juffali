from langchain_google_genai import ChatGoogleGenerativeAI
import json
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Font, Alignment

import os
from dotenv import load_dotenv

load_dotenv()
API_KEY = os.getenv("API_KEY")
# Initialize Gemini
llm = ChatGoogleGenerativeAI(
    google_api_key=API_KEY,
    model="gemini-2.0-flash-exp",
    temperature=0.1,
    max_output_tokens=300
)

# Known Excel files mapped from txt names
known_files = {
    "ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.txt": "ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.xlsx",
    "ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.txt": "ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.xlsx"
}

# Gemini prompt
PROMPT = """
You are a document classifier and information extractor.

You will receive an Arabic input that may be structured or unstructured. You must:
1. Classify whether it belongs to:
   - "ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.txt" â†’ Training Report (fields: Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ù‡ÙˆÙŠØ©ØŒ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŒ Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØŒ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØŒ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…ØŒ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª)
   - "ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.txt" â†’ Activities (fields: Ø§Ù„Ø§Ø³Ù…ØŒ Ø±ÙŠØ§Ø¶ÙŠØŒ ØªØ±ÙÙŠÙ‡ÙŠØŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØŒ Ø³Ø¨Ø§Ø­Ø©ØŒ Ø§Ù„ÙØ¦Ø§ØªØŒ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª)

2. Extract the relevant structured fields regardless of format or order.

ğŸ“Œ Example 1 (Training Report):
Input:
Ø¹Ù…Ø± Ù…Ø§Ø¬Ø¯ Ù…Ù† Ù…ÙˆØ§Ù„ÙŠØ¯ 2006-02-01ØŒ Ø±Ù‚Ù…Ù‡ 1234567890ØŒ ÙŠØªØ¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠ ÙˆÙ‡Ø¯ÙÙ‡ Ø§Ø±ØªØ¯Ø§Ø¡ Ø§Ù„Ù…Ù„Ø§Ø¨Ø³ØŒ Ø­ØµÙ„ Ø¹Ù„Ù‰ 85 ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆÙƒØ§Ù† ØªØ­Ø³Ù†Ù‡ Ù…Ù„Ø­ÙˆØ¸.

Output:
{
  "target_datasheet": "ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.txt",
  "reason": "Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ… ÙˆÙ‡Ø¯Ù ØªØ¯Ø±ÙŠØ¨ÙŠ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ù„ØªÙ‚Ø±ÙŠØ± ØªØ¯Ø±ÙŠØ¨ÙŠ.",
  "structured_data": {
    "name": "Ø¹Ù…Ø± Ù…Ø§Ø¬Ø¯",
    "id": "1234567890",
    "dob": "2006-02-01",
    "training_field": "Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠ",
    "training_goal": "Ø§Ø±ØªØ¯Ø§Ø¡ Ø§Ù„Ù…Ù„Ø§Ø¨Ø³",
    "goal_evaluation": 85,
    "notes": "ØªØ­Ø³Ù†Ù‡ Ù…Ù„Ø­ÙˆØ¸"
  }
}

ğŸ“Œ Example 2 (Activities):
Input:
Ø§Ù„Ø·Ø§Ù„Ø¨ Ø³Ø¹ÙˆØ¯ Ù…Ø§Ø¬Ø¯  ÙŠØ´Ø§Ø±Ùƒ ÙÙŠ ØªÙ…Ø§Ø±ÙŠÙ† Ø§Ù„ØªÙˆØ§Ø²Ù†ØŒ ÙˆÙŠÙØ¶Ù„ Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø±Ø¦ÙŠØ©. ÙŠØ¸Ù‡Ø± Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø£ÙØ¶Ù„ Ø¹Ù†Ø¯ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø¹Ø¨Ø± Ø§Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ø¨ØµØ±ÙŠØ©Ùˆ  ÙŠØªÙØ§Ø¹Ù„ Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø© ØµØºÙŠØ±Ø©. ÙŠÙØ¶Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø¹Ø¯Ø¯ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù† Ø§Ù„Ø£ÙØ±Ø§Ø¯
 . ØªØµÙ†ÙŠÙÙ‡ Ø±ÙŠØ§Ø¶ÙŠ (Ø¬) ÙˆØªØ±ÙÙŠÙ‡ÙŠ (Ø¨) ÙˆØ§Ø¬ØªÙ…Ø§Ø¹ÙŠ (Ø¬) ÙˆØ³Ø¨Ø§Ø­Ø© (Ø¯).
Output:

{
  "target_datasheet": "ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.txt",
  "reason": "Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ù†Ø´Ø·Ø© ÙˆØªØµÙ†ÙŠÙØ§Øª ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ³Ø¨Ø§Ø­Ø© Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØªØµÙ†ÙŠÙ.",
  "structured_data": {
  "name": "Ø³Ø¹ÙˆØ¯ Ù…Ø§Ø¬Ø¯ Ø§Ø¨Ø±Ø§Ù‡ÙŠÙ… Ø§Ù„Ø¹Ø¯ÙˆØ§Ù†",
  "activities": {
    "Ø±ÙŠØ§Ø¶ÙŠ": {
      "category": "Ø¬",
      "note": "ÙŠØ´Ø§Ø±Ùƒ ÙÙŠ ØªÙ…Ø§Ø±ÙŠÙ† Ø§Ù„ØªÙˆØ§Ø²Ù†. ÙŠÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª ÙˆÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø´Ø±Ø§Ù Ù…Ø³ØªÙ…Ø±."
    },
    "ØªØ±ÙÙŠÙ‡ÙŠ": {
      "category": "Ø¨",
      "note": "ÙŠÙØ¶Ù„ Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø¥Ø´Ø§Ø±Ø§Øª Ù…Ø±Ø¦ÙŠØ©. ÙŠØ¸Ù‡Ø± Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø£ÙØ¶Ù„ Ø¹Ù†Ø¯ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø¹Ø¨Ø± Ø§Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„Ø¨ØµØ±ÙŠØ©."
    },
    "Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ": {
      "category": "Ø¬",
      "note": "ÙŠØªÙØ§Ø¹Ù„ Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø© ØµØºÙŠØ±Ø©. ÙŠÙØ¶Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø¹Ø¯Ø¯ Ù…Ø­Ø¯ÙˆØ¯ Ù…Ù† Ø§Ù„Ø£ÙØ±Ø§Ø¯."
    },
    "Ø³Ø¨Ø§Ø­Ø©": {
      "category": "Ø¯",
      "note": "ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¯Ø¹Ù… Ù…Ø§Ø¯ÙŠ ÙÙŠ Ø§Ù„Ù…ÙŠØ§Ù‡. ÙŠØ­ØªØ§Ø¬ Ø¥Ø´Ø±Ø§Ù Ø¯Ø§Ø¦Ù… ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø³Ø¨Ø§Ø­Ø©."
    }
  }
}

Now process this input and return only valid JSON:

\"\"\"{input_text}\"\"\"
"""

# ğŸ” Function to classify and extract data from input text
def classify_input(query: str) -> str:
    try:
        full_prompt = f"{PROMPT}{query}"
        response = llm.invoke(full_prompt)

        if not response or not response.content:
            return "No classification available. Please try again."

        return response.content.strip()

    except Exception as e:
        return f"An error occurred during classification: {e}"

# ğŸ’¾ Function to save extracted data to the actual Excel file
def save_structured_data_to_existing_sheet(data_json: str):
    try:
        # ğŸ”§ Clean Gemini markdown formatting
        cleaned_json = data_json.strip()
        if cleaned_json.startswith("```json"):
            cleaned_json = cleaned_json[7:].strip()
        if cleaned_json.endswith("```"):
            cleaned_json = cleaned_json[:-3].strip()

        open_braces = cleaned_json.count('{')
        close_braces = cleaned_json.count('}')
        if open_braces > close_braces:
            cleaned_json += '}' * (open_braces - close_braces)
            
        data = json.loads(cleaned_json)
        target_file_txt = data.get("target_datasheet")
        structured_data = data.get("structured_data")

        if not target_file_txt or not structured_data:
            return "Invalid Gemini output: missing target_datasheet or structured_data."

        known_files = {
            "ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.txt": "ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.xlsx",
            "ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.txt": "ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.xlsx"
        }

        if target_file_txt=="ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙÙŠØ¯ÙŠ Ø§Ù„Ø³ÙƒÙ† Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø§Ù„ØªØ±ÙÙŠÙ‡ÙŠØ© ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©.txt":
            target_file_xlsx = known_files.get(target_file_txt)
            wb = load_workbook(target_file_xlsx) 

            ws = wb.active  
              
            def find_next_empty_row(ws, col_letter="F", start_row=11):
                row = start_row
                while ws[f"{col_letter}{row}"].value:
                    row += 1
                return row

            row = find_next_empty_row(ws)

            activity_keys = ["Ø±ÙŠØ§Ø¶ÙŠ", "ØªØ±ÙÙŠÙ‡ÙŠ", "Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ", "Ø³Ø¨Ø§Ø­Ø©"]
            columns = ["G", "H", "I", "J"]

            for col, key in zip(columns, activity_keys):
                category = structured_data.get("activities", {}).get(key, {}).get("category", "")
                ws[f"{col}{row}"] = category

            ws[f"F{row}"] = structured_data.get("name", "")

            
            notes_list = []
            for key in activity_keys:
                note = structured_data.get("activities", {}).get(key, {}).get("note")
                if note:
                    notes_list.append(f"- {key}: {note}")

            combined_notes = "\n".join(notes_list)

            cell = ws[f"K{row}"]
            cell.value = combined_notes

            #cell.font = Font(size=36) 
            ws.column_dimensions["K"].width = 200  
            ws.row_dimensions[row].height = 300  


        elif target_file_txt=="ØªÙ‚Ø±ÙŠØ± Ø´Ù‡Ø± Ù…Ø§ÙŠÙˆ.txt":
            target_file_xlsx = known_files.get(target_file_txt)
            wb = load_workbook(target_file_xlsx)
            ws = wb.active

            def find_next_empty_row(ws, col_letter="C", start_row=7):
                row = start_row
                while ws[f"{col_letter}{row}"].value:
                    row += 4 
                return row

            row = find_next_empty_row(ws)
            ws[f"C{row}"] = structured_data.get("name", "")
            ws[f"D{row}"] = structured_data.get("id", "")
            ws[f"E{row}"] = structured_data.get("dob", "")
            field_row_map = {
                "Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠ": 0,
                "Ø§Ù„Ø¥Ø¯Ø±Ø§ÙƒÙŠ": 1,
                "Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ": 2,
                "Ø§Ù„ØªÙˆØ§ØµÙ„": 3
            }

            field = structured_data.get("training_field")
            if field in field_row_map:
                offset = field_row_map[field]
                target_row = row + offset

                ws[f"G{target_row}"] = structured_data.get("training_goal", "")
                

                evaluation = structured_data.get("goal_evaluation")

                if evaluation not in (None, ""):
                    try:
                        evaluation = int(evaluation)  

                        if evaluation <= 60:
                            ws[f"J{target_row}"] = evaluation
                        elif 80 <= evaluation < 100:
                            ws[f"I{target_row}"] = evaluation
                        elif evaluation >= 100:
                            ws[f"H{target_row}"] = evaluation

                    except (ValueError, TypeError):
                        pass

                ws[f"K{target_row}"] = structured_data.get("notes", "")

        else:
            return f"âŒ Sheet for {target_file_txt} not found in current directory."
        

        wb.save(target_file_xlsx)
        print("âœ…")
        return f"âœ… Data saved to existing file: {target_file_xlsx}"
    

    except Exception as e:
        return f"âŒ Error: {e}"

# ğŸš€ Main Execution
def main(user_input):
    #user_input = input("Enter any sentence in Arabic (structured or unstructured):\n")
    class_file = classify_input(user_input)

    print("\nğŸ”¤ Gemini Response:")
    print(class_file)

    print("\nğŸ’¾ Saving to Excel...")
    result = save_structured_data_to_existing_sheet(class_file)
    print(result)
    return result
